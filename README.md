# Figment Take-Home Test

Minimal dbt + Postgres stack with Dev Container, unit-tests and CI.

---

## ğŸš€ Quick Start (VS Code Dev Container)

### Requirements
- Visual Studio Code with "Dev Containers" extension
- Docker Desktop (macOS/Windows) or Docker Engine (Linux)
- Docker Compose
- Port 5432 available for PostgreSQL

1. Press **F1 â†’ "Dev Containers: Reopen in Container"** or **select the icon on the left bottom corner of VS Code â†’ "Open in Container"**  
   VS Code builds `.devcontainer/Dockerfile`, which already includes:

   * Python 3.11, **pipenv**, dbt 1.7 +, pytest
   * Postgres service wired to `profiles.yml`

2. When the build finishes the integrated terminal drops you into an
   **Pipenv** aware environment.
   Run your usual commands:

   ```bash
   make build                       # seeds â†’ run â†’ test
   make test                        # Run dbt tests
   make docs                        # Explore lineage: ethereum_rewards_raw âœ stg_* âœ int_* âœ fct_*.

   ```

That's itâ€”no extra installs; everything is baked into the image.
Devcontainer also initiates the Postegres DB.

---

## âš™ï¸ CI

* **Workflow:** `.github/workflows/ci.yml`
* **Steps:** checkout â†’ build Dev Container â†’ `pytest` â†’ `dbt build --warn-error`
* Passes or blocks every push / pull-request to `main`.

---

## ğŸ—‚ï¸ Key Files

```
.devcontainer/                # Dockerfile + devcontainer.json (dependencies baked in)
docker-compose.yml            # Postgres build context
models/                       # staging/ â†’ intermediate/ â†’ marts/ + Data and Unit tests
macros/                       # reusable Jinja 
tests/                        # Singular tests
seeds/                        # CSVs for small fixed tables used as support tables
.github/workflows/ci.yml      # Github Actions Continuous Integration workflow
```

---

## ğŸ”§ Common Commands

```bash
pipenv run dbt build                        # compile + run + test
pipenv run dbt build -s staging.            # only staging layer
pipenv run pytest -q                        # run unit-tests
```

Everything is idempotent and atomicâ€”rerun at will.

## Project Structure
```
dbt_project/                
â”œâ”€â”€ .devcontainer/            # Dev Containers
â”‚   â”œâ”€â”€ devcontainer.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/            
â”‚       â””â”€â”€ ci.yml            # CI (lint, dbt build, unit-tests)
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ postgres/             # Local Postgres image build context
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ init-db.sh        # Init script
â”‚   â””â”€â”€ dbt/                  # Slim dbt-runner image
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml        # Spins up Postgres + dbt
â”œâ”€â”€ Pipfile                   # Python dependencies
â”œâ”€â”€ profiles.yml              # Maps to Postgres service
â”œâ”€â”€ dbt_project.yml           # Dbt configs
â”œâ”€â”€ macros/                   # Re-usable SQL macros
â”œâ”€â”€ models/                   # Data models
â”‚   â”œâ”€â”€ staging/              # Staging cleanse
â”‚   â”‚   â””â”€â”€ ethereum/
â”‚   â”‚       â”œâ”€â”€ _staging_ethereum__sources.yml
â”‚   â”‚       â”œâ”€â”€ stg_ethereum_rewards.sql
â”‚   â”‚       â””â”€â”€ stg_ethereum_rewards_schema.yml            # generic data tests + docs
â”‚   â”œâ”€â”€ intermediate/         # Intermediate tables
â”‚   â”‚   â””â”€â”€ ethereum/
â”‚   â”‚       â”œâ”€â”€ int_rewards_enriched.sql
â”‚   â”‚       â”œâ”€â”€ int_rewards_enriched_schema.sql            # generic data tests + docs
|   |       â”œâ”€â”€ int_rewards_daily_agg.sql
â”‚   â”‚       â””â”€â”€ int_rewards_daily_a_schema.yml             # generic data tests + docs
â”‚   â”œâ”€â”€ marts/                # Incremental daily model
â”‚   |    â””â”€â”€ ethereum/
â”‚   |       â”œâ”€â”€ fct_ethereum_rewards_daily.sql
â”‚   |       â””â”€â”€ fct_ethereum_rewards_daily_schema.yml      # generic data tests + docs
|   â””â”€â”€ unit_tests/  
â”œâ”€â”€ tests/                    # Unit tests
â”‚   â””â”€â”€ data/                 # Singular data tests
â”œâ”€â”€ seeds/                    # Reference seeds
â”œâ”€â”€ snapshots/                # Slowly-changing dimensions
â”œâ”€â”€ analyses/                 # Ad-hoc or interview write-ups
â””â”€â”€ README.md                 # How to run locally (dev-container)
```

## Why Intermediate Layer?

| Layer               | Responsibility                     | Benefit                                                         |
| ------------------- | ---------------------------------- | --------------------------------------------------------------- |
| **I1 â€“ enriched**   | Do all *row-level* math once       | Central place for currency/exponent fixes; easier to unit-test  |
| **I2 â€“ daily_agg**  | Pure *aggregation*                 | Keeps final model thin; reusable for other marts (e.g., weekly) |
| **Fact table**      | Incremental load & running balance | Smallest possible footprint for the expensive `merge`           |

This separation guarantees:

- Idempotency â€“ rerunning any upstream model never double-counts; unique keys enforce that.
- Debuggability â€“ it is possible  to demo numbers at each hop.
- Performance â€“ only one model (ethereum_rewards_daily) is incremental/merged; others are simple selects.

## Materialization Strategy

| Type            | Pros                                          | Cons                                | Best spots                            |
| --------------- | --------------------------------------------- | ----------------------------------- | ------------------------------------- |
| **view**        | Zero storage, always fresh                    | Re-computes every read              | `int_rewards_daily_agg`               |
| **table**       | Fast downstream queries                       | Rebuild cost on `dbt run -m +model` | `stg_ethereum_rewards` and `int_rewards_enriched`                |
| **incremental** | Adds only new partitions, avoids full rebuild | Extra complexity; needs unique keys | `fact_ethereum_rewards_daily`         |
| **ephemeral**   | Inlined CTE (no object)                       | Large SQL + no re-use               | Not used â€“ we want inspectable tables |
